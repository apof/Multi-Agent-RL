{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Commnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMun6tq+m9b5b//COLJbTPk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apof/Multi-Agent-RL/blob/main/Commnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31BIhfT1ECpj"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKZQyD6iE035"
      },
      "source": [
        "AGENTS_NUMBER = 10\n",
        "ACTIONS_NUMBER = 5\n",
        "STATE_LENGTH = 50\n",
        "ENCODING_LENGTH = 200\n",
        "COMMUNICATION_STEPS = 3\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAc2h_v2MDz1"
      },
      "source": [
        "class ReplayBuffer(object):\n",
        "  def __init__(self,max_size,input_space,n_actions):\n",
        "    self.mem_size = max_size\n",
        "    self.mem_cntr = 0\n",
        "    self.state_memory = np.zeros((self.mem_size,*input_shape))\n",
        "    self.new_state_memory = np.zeros((self.mem_size,*input_shape))\n",
        "    self.action_memory = np.zeros((self.mem_size,n_actions))\n",
        "    self.reward_memory = np.zeros(self.mem_size)\n",
        "    self.terminal_memory = np.zeros(self.memsize,dtype=np.float32)\n",
        "\n",
        "  def store_transition(self,state,action,reward,state_,done):\n",
        "    index = self.mem_cntr%self.mem_size\n",
        "    self.state_memory[index] = state\n",
        "    self.new_state_memory[index] = state_\n",
        "    self.reward_memory[index] = reward\n",
        "    self.terminal_memory[index] = 1-done\n",
        "    self.mem_cntr += 1\n",
        "\n",
        "  def sample_buffer(self,batch_size):\n",
        "    max_mem = min(self.memcntr,self.mem_size)\n",
        "    batch = np.random.choice(max_mem,batch_size)\n",
        "    states = self.state_memory[batch]\n",
        "    next_states = self.new_state_memory[batch]\n",
        "    actions = self.action_memory[batch]\n",
        "    rewards = self.reward_memory[batch]\n",
        "    terminal = self.terminal_memory[batch]\n",
        "    return states,actions,rewards,new_states,terminal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBasafK0-G_o"
      },
      "source": [
        "## this network gets the output of the commnet and applies a value decomposition nework on the top of it\n",
        "class VDN(nn.Module):\n",
        "\n",
        "  def __init__(self,linear_dim = 300,device = None):\n",
        "    super().__init__()\n",
        "    print(\"ok\")\n",
        "    self.device = device\n",
        "    print(self.device)\n",
        "    self.commnet = CommNet(STATE_LENGTH,ENCODING_LENGTH,AGENTS_NUMBER,COMMUNICATION_STEPS)\n",
        "    self.linear_dim = linear_dim\n",
        "    self.value_stream = nn.ModuleList([nn.Sequential(nn.Linear(ENCODING_LENGTH, self.linear_dim),nn.ReLU(),nn.Linear(self.linear_dim,1)) for i in range(AGENTS_NUMBER)])\n",
        "    self.advantage_stream = nn.ModuleList([nn.Sequential(nn.Linear(ENCODING_LENGTH, self.linear_dim),nn.ReLU(),nn.Linear(self.linear_dim,5)) for i in range(AGENTS_NUMBER)])\n",
        "    self.to(device)\n",
        "\n",
        "  def forward(self,states):\n",
        "    encoded_state = self.commnet(states)\n",
        "\n",
        "    out = []\n",
        "    for agent_index in range(AGENTS_NUMBER):\n",
        "      value = self.value_stream[agent_index](encoded_state[:,agent_index,:])\n",
        "      advantage = self.advantage_stream[agent_index](encoded_state[:,agent_index,:])\n",
        "      qvals = value + (advantage - advantage.mean())\n",
        "      qvals = torch.reshape(qvals,(qvals.shape[0],1,qvals.shape[1]))\n",
        "      out.append(qvals)\n",
        "    out = torch.cat(out,axis=1)\n",
        "\n",
        "    print(\"Forward pass: \" + str(out.shape))\n",
        "\n",
        "    return out\n",
        "\n",
        "  def get_current(self,states,actions):\n",
        "\n",
        "    print(actions)\n",
        "\n",
        "    ## get the current action based on the policy network\n",
        "    q_vals = self.forward(states)\n",
        "    a = []\n",
        "    for i in range(AGENTS_NUMBER):\n",
        "      a.append(q_vals[i].gather(dim=1, index=actions[i].unsqueeze(-1)))\n",
        "\n",
        "    ##sum the action values across all the agents\n",
        "    joint_actions = torch.zeros(a[0].size())\n",
        "\n",
        "    for i in range(AGENTS_NUMBER):\n",
        "      joint_actions = torch.add(joint_actions,a[i])\n",
        "\n",
        "    print(\"Joint Values: \" + str(joint_actions.shape))\n",
        "\n",
        "    return joint_actions\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52bahL0-ElM4"
      },
      "source": [
        "class CommNet(nn.Module):\n",
        "  def __init__(self,state_dimension,encoding_dimension,agents_num,communication_steps,output_type = 'actor'):\n",
        "    super().__init__()\n",
        "    self.state_dimension = state_dimension\n",
        "    self.encoding_dimension = encoding_dimension\n",
        "    self.agents_num = agents_num\n",
        "    self.communication_steps = communication_steps\n",
        "    ## define if the outpout of the network is actor or critic type\n",
        "    self.output_type = output_type\n",
        "\n",
        "    self.encoding_layer = nn.Sequential(nn.Linear(self.state_dimension, self.encoding_dimension),nn.ReLU())\n",
        "    self.WH_layer = nn.ModuleList([nn.Linear(self.encoding_dimension, self.encoding_dimension) for i in range(self.communication_steps)])\n",
        "    self.WC_layer = nn.ModuleList([nn.Linear(self.encoding_dimension, self.encoding_dimension) for i in range(self.communication_steps)])\n",
        "\n",
        "\n",
        "  def encoding_step(self,states):\n",
        "    print(\"Input shape: \" + str(states.shape))\n",
        "    ## encode the state of every agent\n",
        "    encoded_inputs = []\n",
        "    for agent_index in range(self.agents_num):\n",
        "      encoded_input = self.encoding_layer(states[:,agent_index,:])\n",
        "      encoded_input = torch.reshape(encoded_input,(encoded_input.shape[0],1,encoded_input.shape[1]))\n",
        "      encoded_inputs.append(encoded_input)\n",
        "    encoded_inputs = torch.cat(encoded_inputs,axis=1)\n",
        "    print(\"Encoded Inputs shape: \" + str(encoded_inputs.shape))\n",
        "    return encoded_inputs\n",
        "\n",
        "  def f(self,h,c,step_index):\n",
        "    ## decide which weight to use\n",
        "    return torch.tanh(self.WH_layer[step_index](h)  + self.WC_layer[step_index](c))\n",
        "\n",
        "  def communication_step(self,H,C,step_index):\n",
        "\n",
        "    print(\"Communication step: \" + str(step_index))\n",
        "\n",
        "    ## compute the next H\n",
        "    next_H = []\n",
        "    for agent_index in range(self.agents_num):\n",
        "      h = H[:,agent_index,:]\n",
        "      c = C[:,agent_index,:]\n",
        "      next_h = self.f(h,c,step_index)\n",
        "      next_h = torch.reshape(next_h,(next_h.shape[0],1,next_h.shape[1]))\n",
        "      next_H.append(next_h)\n",
        "    next_H = torch.cat(next_H,axis = 1)\n",
        "\n",
        "    print(next_H.shape)\n",
        "\n",
        "    next_C = []\n",
        "    for i in range(self.agents_num):\n",
        "      next_c = []\n",
        "      for j in range(self.agents_num):\n",
        "        if (i!=j):\n",
        "          next_c.append(next_H[:,j,:])\n",
        "      stacked_c = torch.stack(next_c,axis = 0)\n",
        "      next_c = torch.mean(stacked_c,axis = 0)\n",
        "      next_c = torch.reshape(next_c,(next_c.shape[0],1,next_c.shape[1]))\n",
        "      next_C.append(next_c)\n",
        "    next_C = torch.cat(next_C,axis = 1)\n",
        "\n",
        "    print(next_C.shape)\n",
        "\n",
        "    return next_H, next_C\n",
        "\n",
        "  def forward(self,states):\n",
        "    ## encode the state for every agent\n",
        "    encoded_states = self.encoding_step(states)\n",
        "    ## communication steps\n",
        "    ## define the first communication vector H filled with zeros\n",
        "    C0 = torch.zeros_like(encoded_states)\n",
        "    H = encoded_states\n",
        "    C = C0\n",
        "    for step in range(self.communication_steps):\n",
        "      H_new, C_new = self.communication_step(H,C,step)\n",
        "      C = C_new\n",
        "      H = H_new\n",
        "\n",
        "    return H"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qac37JRaGfO5"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYtLBi3rbmff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beba143f-a018-4430-862f-b84aed267d57"
      },
      "source": [
        "model = VDN(device = device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ok\n",
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNO4ed2uvHvl"
      },
      "source": [
        "states = np.random.rand(BATCH_SIZE,AGENTS_NUMBER,STATE_LENGTH)\n",
        "actions = np.zeros((BATCH_SIZE,AGENTS_NUMBER,ACTIONS_NUMBER))\n",
        "states = torch.from_numpy(states).float().to(model.device)\n",
        "actions = torch.from_numpy(actions).to(model.device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPq4S01QFNzV",
        "outputId": "8654decb-1a8f-43f2-fe56-808031e4492d"
      },
      "source": [
        "print(actions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.]]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJHycwogc0SA",
        "outputId": "2f824d61-d14b-4ae7-ba39-4f95ccef7c4d"
      },
      "source": [
        "model.forward(states)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([64, 10, 50])\n",
            "Encoded Inputs shape: torch.Size([64, 10, 200])\n",
            "Communication step: 0\n",
            "torch.Size([64, 10, 200])\n",
            "torch.Size([64, 10, 200])\n",
            "Communication step: 1\n",
            "torch.Size([64, 10, 200])\n",
            "torch.Size([64, 10, 200])\n",
            "Communication step: 2\n",
            "torch.Size([64, 10, 200])\n",
            "torch.Size([64, 10, 200])\n",
            "Forward pass: torch.Size([64, 10, 5])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.0374, -0.0230, -0.0813,  0.0024, -0.0613],\n",
              "         [-0.0678,  0.0731,  0.0066,  0.0272, -0.0667],\n",
              "         [ 0.0655,  0.1108,  0.0431,  0.0280,  0.0671],\n",
              "         ...,\n",
              "         [-0.0089,  0.0671,  0.0048,  0.0753, -0.0213],\n",
              "         [-0.0012, -0.0164,  0.0966, -0.0161,  0.0056],\n",
              "         [ 0.0287, -0.0070, -0.0861,  0.0554,  0.0214]],\n",
              "\n",
              "        [[-0.0354, -0.0126, -0.0708,  0.0045, -0.0500],\n",
              "         [-0.0750,  0.0682,  0.0045,  0.0318, -0.0701],\n",
              "         [ 0.0531,  0.0985,  0.0368,  0.0311,  0.0753],\n",
              "         ...,\n",
              "         [-0.0095,  0.0749,  0.0254,  0.0841, -0.0283],\n",
              "         [ 0.0078, -0.0139,  0.0864, -0.0179,  0.0156],\n",
              "         [ 0.0353, -0.0152, -0.0835,  0.0597,  0.0250]],\n",
              "\n",
              "        [[-0.0292,  0.0027, -0.0664,  0.0072, -0.0504],\n",
              "         [-0.0735,  0.0713,  0.0009,  0.0189, -0.0749],\n",
              "         [ 0.0571,  0.1094,  0.0394,  0.0261,  0.0690],\n",
              "         ...,\n",
              "         [-0.0225,  0.0641,  0.0026,  0.0702, -0.0363],\n",
              "         [-0.0008, -0.0143,  0.0947, -0.0185,  0.0068],\n",
              "         [ 0.0214, -0.0184, -0.0838,  0.0375,  0.0198]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-0.0378, -0.0093, -0.0790,  0.0069, -0.0688],\n",
              "         [-0.0716,  0.0600,  0.0067,  0.0193, -0.0658],\n",
              "         [ 0.0598,  0.1081,  0.0321,  0.0275,  0.0674],\n",
              "         ...,\n",
              "         [-0.0045,  0.0698,  0.0265,  0.0842, -0.0203],\n",
              "         [-0.0003, -0.0071,  0.1061, -0.0098,  0.0126],\n",
              "         [ 0.0241, -0.0179, -0.0915,  0.0469,  0.0219]],\n",
              "\n",
              "        [[-0.0387, -0.0173, -0.0781,  0.0015, -0.0712],\n",
              "         [-0.0753,  0.0708,  0.0080,  0.0246, -0.0738],\n",
              "         [ 0.0785,  0.1238,  0.0524,  0.0412,  0.0833],\n",
              "         ...,\n",
              "         [-0.0031,  0.0809,  0.0238,  0.0812, -0.0222],\n",
              "         [ 0.0078, -0.0119,  0.1050, -0.0099,  0.0104],\n",
              "         [ 0.0280, -0.0130, -0.0802,  0.0413,  0.0255]],\n",
              "\n",
              "        [[-0.0293, -0.0031, -0.0789,  0.0053, -0.0574],\n",
              "         [-0.0732,  0.0598,  0.0069,  0.0264, -0.0787],\n",
              "         [ 0.0633,  0.1089,  0.0431,  0.0292,  0.0697],\n",
              "         ...,\n",
              "         [-0.0066,  0.0677,  0.0139,  0.0692, -0.0381],\n",
              "         [ 0.0080, -0.0147,  0.1021, -0.0135,  0.0115],\n",
              "         [ 0.0284, -0.0126, -0.0779,  0.0495,  0.0274]]],\n",
              "       grad_fn=<CatBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ybeH3VUMEOmy",
        "outputId": "f7d4851b-7704-4b57-e27b-35f98ee56254"
      },
      "source": [
        "model.get_current(states,actions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0.]]], dtype=torch.float64)\n",
            "Input shape: torch.Size([64, 10, 50])\n",
            "Encoded Inputs shape: torch.Size([64, 10, 200])\n",
            "Communication step: 0\n",
            "torch.Size([64, 10, 200])\n",
            "torch.Size([64, 10, 200])\n",
            "Communication step: 1\n",
            "torch.Size([64, 10, 200])\n",
            "torch.Size([64, 10, 200])\n",
            "Communication step: 2\n",
            "torch.Size([64, 10, 200])\n",
            "torch.Size([64, 10, 200])\n",
            "Forward pass: torch.Size([64, 10, 5])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-150-b57b31ff052c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-143-33e95d2ca943>\u001b[0m in \u001b[0;36mget_current\u001b[0;34m(self, states, actions)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAGENTS_NUMBER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m       \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_vals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m##sum the action values across all the agents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: gather_out_cpu(): Expected dtype int64 for index"
          ]
        }
      ]
    }
  ]
}