{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Commnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPm2QsfoJOGwd6mcKxI53Sw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apof/Multi-Agent-RL/blob/main/Commnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31BIhfT1ECpj"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKZQyD6iE035"
      },
      "source": [
        "AGENTS_NUMBER = 5\n",
        "ACTIONS_NUMBER = 5\n",
        "STATE_LENGTH = 50\n",
        "ENCODING_LENGTH = 200\n",
        "COMMUNICATION_STEPS = 3\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAc2h_v2MDz1"
      },
      "source": [
        "class ReplayBuffer(object):\n",
        "  def __init__(self,max_size,input_space,n_actions):\n",
        "    self.mem_size = max_size\n",
        "    self.mem_cntr = 0\n",
        "    self.state_memory = np.zeros((self.mem_size,*input_shape))\n",
        "    self.new_state_memory = np.zeros((self.mem_size,*input_shape))\n",
        "    self.action_memory = np.zeros((self.mem_size,n_actions))\n",
        "    self.reward_memory = np.zeros(self.mem_size)\n",
        "    self.terminal_memory = np.zeros(self.memsize,dtype=np.float32)\n",
        "\n",
        "  def store_transition(self,state,action,reward,state_,done):\n",
        "    index = self.mem_cntr%self.mem_size\n",
        "    self.state_memory[index] = state\n",
        "    self.new_state_memory[index] = state_\n",
        "    self.reward_memory[index] = reward\n",
        "    self.terminal_memory[index] = 1-done\n",
        "    self.mem_cntr += 1\n",
        "\n",
        "  def sample_buffer(self,batch_size):\n",
        "    max_mem = min(self.memcntr,self.mem_size)\n",
        "    batch = np.random.choice(max_mem,batch_size)\n",
        "    states = self.state_memory[batch]\n",
        "    next_states = self.new_state_memory[batch]\n",
        "    actions = self.action_memory[batch]\n",
        "    rewards = self.reward_memory[batch]\n",
        "    terminal = self.terminal_memory[batch]\n",
        "    return states,actions,rewards,new_states,terminal"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8ArXk1wP9wK"
      },
      "source": [
        "class CriticNetwork(nn.Module):\n",
        "  def __init__(self,beta = 0.001,input_dims = ENCODING_LENGTH,fc1_dims = 300,fc2_dims = 30,n_actions = ACTIONS_NUMBER,device = None):\n",
        "    super(CriticNetwork, self).__init__()\n",
        "    self.input_dims = input_dims\n",
        "    self.fc1_dims = fc1_dims\n",
        "    self.fc2_dims = fc2_dims\n",
        "    self.n_actions = n_actions\n",
        "    self.device = device\n",
        "\n",
        "    self.commnet = CommNet(STATE_LENGTH,ENCODING_LENGTH,AGENTS_NUMBER,COMMUNICATION_STEPS)\n",
        "\n",
        "    ## define a fully connected layer that processes the encoded states\n",
        "    self.fc1 = nn.Linear(self.input_dims,self.fc1_dims)\n",
        "    self.fc2 = nn.Linear(self.fc1_dims,self.fc2_dims)\n",
        "    ## define a layer that processes the action values\n",
        "    self.action_value = nn.Linear(self.n_actions,self.fc2_dims)\n",
        "    ## define a q value layer\n",
        "    self.q = nn.Linear(self.fc2_dims,1)\n",
        "\n",
        "    ## define the optimiser\n",
        "    self.optimiser = optim.Adam(self.parameters(),lr=beta)\n",
        "\n",
        "    self.to(self.device)\n",
        "\n",
        "  def forward(self,state,action):\n",
        "\n",
        "    encoded_state = self.commnet(state)\n",
        "\n",
        "    ## process the encoded state\n",
        "    state_out = []\n",
        "    for agent_index in range(self.n_actions):\n",
        "      state_value = self.fc1(encoded_state[:,agent_index,:])\n",
        "      state_value = F.relu(state_value)\n",
        "      state_value = self.fc2(state_value)\n",
        "      state_value = F.relu(state_value)\n",
        "      state_value = torch.reshape(state_value,(state_value.shape[0],1,state_value.shape[1]))\n",
        "      state_out.append(state_value)\n",
        "    state_out = torch.cat(state_out,axis=1)\n",
        "\n",
        "    ## process the actions\n",
        "    actions_out = []\n",
        "    for agent_index in range(self.n_actions):\n",
        "      action_value = F.relu(self.action_value(action[:,agent_index,:]))\n",
        "      action_value = torch.reshape(action_value,(action_value.shape[0],1,action_value.shape[1]))\n",
        "      actions_out.append(action_value)\n",
        "    actions_out = torch.cat(actions_out,axis=1)\n",
        "\n",
        "    ## combine states and actions\n",
        "    state_action_value = F.relu(torch.add(state_out,actions_out))\n",
        "\n",
        "    q_out = []\n",
        "    for agent_index in range(self.n_actions):\n",
        "      q_value = F.relu(self.q(state_action_value[:,agent_index,:]))\n",
        "      q_value = torch.reshape(q_value,(q_value.shape[0],1,q_value.shape[1]))\n",
        "      q_out.append(q_value)\n",
        "    q_out = torch.cat(q_out,axis=1)\n",
        "\n",
        "    print(\"Critic Network output: \" + str(q_out.shape))\n",
        "\n",
        "    return q_out"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuGXCwMBkYPU"
      },
      "source": [
        "class ActorNetwork(nn.Module):\n",
        "  def __init__(self,beta = 0.001,input_dims = ENCODING_LENGTH,fc1_dims = 300,fc2_dims = 30,n_actions = AGENTS_NUMBER,device = None):\n",
        "    super(ActorNetwork, self).__init__()\n",
        "    self.input_dims = input_dims\n",
        "    self.fc1_dims = fc1_dims\n",
        "    self.fc2_dims = fc2_dims\n",
        "    self.n_actions = n_actions\n",
        "    self.device = device\n",
        "\n",
        "    self.commnet = CommNet(STATE_LENGTH,ENCODING_LENGTH,AGENTS_NUMBER,COMMUNICATION_STEPS)\n",
        "\n",
        "    ## define a fully connected layer that processes the encoded states\n",
        "    self.fc1 = nn.Linear(self.input_dims,self.fc1_dims)\n",
        "    self.fc2 = nn.Linear(self.fc1_dims,self.fc2_dims)\n",
        "    self.fc3 = nn.Linear(self.fc2_dims,self.n_actions)\n",
        "\n",
        "    ## define the optimiser\n",
        "    self.optimiser = optim.Adam(self.parameters(),lr=beta)\n",
        "\n",
        "    self.to(self.device)\n",
        "\n",
        "  def forward(self,state):\n",
        "\n",
        "    encoded_state = self.commnet(state)\n",
        "\n",
        "    ## process the encoded state\n",
        "    out = []\n",
        "    for agent_index in range(self.n_actions):\n",
        "      state_value = F.relu(self.fc1(encoded_state[:,agent_index,:]))\n",
        "      state_value = F.relu(self.fc2(state_value))\n",
        "      state_value = torch.tanh(self.fc3(state_value))\n",
        "      state_value = torch.reshape(state_value,(state_value.shape[0],1,state_value.shape[1]))\n",
        "      out.append(state_value)\n",
        "    out = torch.cat(out,axis=1)\n",
        "\n",
        "    print(\"Actor Network output: \" + str(out.shape))\n",
        "\n",
        "    return out"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52bahL0-ElM4"
      },
      "source": [
        "class CommNet(nn.Module):\n",
        "  def __init__(self,state_dimension,encoding_dimension,agents_num,communication_steps,output_type = 'actor'):\n",
        "    super().__init__()\n",
        "    self.state_dimension = state_dimension\n",
        "    self.encoding_dimension = encoding_dimension\n",
        "    self.agents_num = agents_num\n",
        "    self.communication_steps = communication_steps\n",
        "    ## define if the outpout of the network is actor or critic type\n",
        "    self.output_type = output_type\n",
        "\n",
        "    self.encoding_layer = nn.Sequential(nn.Linear(self.state_dimension, self.encoding_dimension),nn.ReLU())\n",
        "    self.WH_layer = nn.ModuleList([nn.Linear(self.encoding_dimension, self.encoding_dimension) for i in range(self.communication_steps)])\n",
        "    self.WC_layer = nn.ModuleList([nn.Linear(self.encoding_dimension, self.encoding_dimension) for i in range(self.communication_steps)])\n",
        "\n",
        "\n",
        "  def encoding_step(self,states):\n",
        "    print(\"Input shape: \" + str(states.shape))\n",
        "    ## encode the state of every agent\n",
        "    encoded_inputs = []\n",
        "    for agent_index in range(self.agents_num):\n",
        "      encoded_input = self.encoding_layer(states[:,agent_index,:])\n",
        "      encoded_input = torch.reshape(encoded_input,(encoded_input.shape[0],1,encoded_input.shape[1]))\n",
        "      encoded_inputs.append(encoded_input)\n",
        "    encoded_inputs = torch.cat(encoded_inputs,axis=1)\n",
        "    print(\"Encoded Inputs shape: \" + str(encoded_inputs.shape))\n",
        "    return encoded_inputs\n",
        "\n",
        "  def f(self,h,c,step_index):\n",
        "    ## decide which weight to use\n",
        "    return torch.tanh(self.WH_layer[step_index](h)  + self.WC_layer[step_index](c))\n",
        "\n",
        "  def communication_step(self,H,C,step_index):\n",
        "\n",
        "    print(\"Communication step: \" + str(step_index))\n",
        "\n",
        "    ## compute the next H\n",
        "    next_H = []\n",
        "    for agent_index in range(self.agents_num):\n",
        "      h = H[:,agent_index,:]\n",
        "      c = C[:,agent_index,:]\n",
        "      next_h = self.f(h,c,step_index)\n",
        "      next_h = torch.reshape(next_h,(next_h.shape[0],1,next_h.shape[1]))\n",
        "      next_H.append(next_h)\n",
        "    next_H = torch.cat(next_H,axis = 1)\n",
        "\n",
        "    print(next_H.shape)\n",
        "\n",
        "    next_C = []\n",
        "    for i in range(self.agents_num):\n",
        "      next_c = []\n",
        "      for j in range(self.agents_num):\n",
        "        if (i!=j):\n",
        "          next_c.append(next_H[:,j,:])\n",
        "      stacked_c = torch.stack(next_c,axis = 0)\n",
        "      next_c = torch.mean(stacked_c,axis = 0)\n",
        "      next_c = torch.reshape(next_c,(next_c.shape[0],1,next_c.shape[1]))\n",
        "      next_C.append(next_c)\n",
        "    next_C = torch.cat(next_C,axis = 1)\n",
        "\n",
        "    print(next_C.shape)\n",
        "\n",
        "    return next_H, next_C\n",
        "\n",
        "  def forward(self,states):\n",
        "    ## encode the state for every agent\n",
        "    encoded_states = self.encoding_step(states)\n",
        "    ## communication steps\n",
        "    ## define the first communication vector H filled with zeros\n",
        "    C0 = torch.zeros_like(encoded_states)\n",
        "    H = encoded_states\n",
        "    C = C0\n",
        "    for step in range(self.communication_steps):\n",
        "      H_new, C_new = self.communication_step(H,C,step)\n",
        "      C = C_new\n",
        "      H = H_new\n",
        "\n",
        "    return H"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qac37JRaGfO5"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYtLBi3rbmff"
      },
      "source": [
        "CriticNetwork = CriticNetwork(device = device)\n",
        "ActorNetwork = ActorNetwork(device = device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNO4ed2uvHvl"
      },
      "source": [
        "states = np.random.rand(BATCH_SIZE,AGENTS_NUMBER,STATE_LENGTH)\n",
        "actions = np.random.rand(BATCH_SIZE,AGENTS_NUMBER,ACTIONS_NUMBER)\n",
        "states = torch.from_numpy(states).float().to(CriticNetwork.device)\n",
        "actions = torch.from_numpy(actions).float().to(CriticNetwork.device)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJHycwogc0SA",
        "outputId": "62bb5568-fbc7-4328-bacc-76f4f727041c"
      },
      "source": [
        "critic_out = CriticNetwork.forward(states,actions)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([64, 5, 50])\n",
            "Encoded Inputs shape: torch.Size([64, 5, 200])\n",
            "Communication step: 0\n",
            "torch.Size([64, 5, 200])\n",
            "torch.Size([64, 5, 200])\n",
            "Communication step: 1\n",
            "torch.Size([64, 5, 200])\n",
            "torch.Size([64, 5, 200])\n",
            "Communication step: 2\n",
            "torch.Size([64, 5, 200])\n",
            "torch.Size([64, 5, 200])\n",
            "Critic Network output: torch.Size([64, 5, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYZTKRHQls_6",
        "outputId": "412d9027-ef38-4744-bc71-ced022457160"
      },
      "source": [
        "actor_out = ActorNetwork.forward(states)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([64, 5, 50])\n",
            "Encoded Inputs shape: torch.Size([64, 5, 200])\n",
            "Communication step: 0\n",
            "torch.Size([64, 5, 200])\n",
            "torch.Size([64, 5, 200])\n",
            "Communication step: 1\n",
            "torch.Size([64, 5, 200])\n",
            "torch.Size([64, 5, 200])\n",
            "Communication step: 2\n",
            "torch.Size([64, 5, 200])\n",
            "torch.Size([64, 5, 200])\n",
            "Actor Network output: torch.Size([64, 5, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}