{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Commnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNf51Zr8PNG5a/91ZuYA+xL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apof/Multi-Agent-RL/blob/main/Commnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31BIhfT1ECpj"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKZQyD6iE035"
      },
      "source": [
        "AGENTS_NUMBER = 2\n",
        "ACTIONS_NUMBER = 5\n",
        "STATE_LENGTH = 50\n",
        "ENCODING_LENGTH = 200\n",
        "COMMUNICATION_STEPS = 3\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAc2h_v2MDz1"
      },
      "source": [
        "class ReplayBuffer(object):\n",
        "  def __init__(self,max_size,input_space,n_actions):\n",
        "    self.mem_size = max_size\n",
        "    self.mem_cntr = 0\n",
        "    self.state_memory = np.zeros((self.mem_size,*input_shape))\n",
        "    self.new_state_memory = np.zeros((self.mem_size,*input_shape))\n",
        "    self.action_memory = np.zeros((self.mem_size,n_actions))\n",
        "    self.reward_memory = np.zeros(self.mem_size)\n",
        "    self.terminal_memory = np.zeros(self.memsize,dtype=np.float32)\n",
        "\n",
        "  def store_transition(self,state,action,reward,state_,done):\n",
        "    index = self.mem_cntr%self.mem_size\n",
        "    self.state_memory[index] = state\n",
        "    self.new_state_memory[index] = state_\n",
        "    self.reward_memory[index] = reward\n",
        "    self.terminal_memory[index] = 1-done\n",
        "    self.mem_cntr += 1\n",
        "\n",
        "  def sample_buffer(self,batch_size):\n",
        "    max_mem = min(self.memcntr,self.mem_size)\n",
        "    batch = np.random.choice(max_mem,batch_size)\n",
        "    states = self.state_memory[batch]\n",
        "    next_states = self.new_state_memory[batch]\n",
        "    actions = self.action_memory[batch]\n",
        "    rewards = self.reward_memory[batch]\n",
        "    terminal = self.terminal_memory[batch]\n",
        "    return states,actions,rewards,new_states,terminal"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBasafK0-G_o"
      },
      "source": [
        "## this network gets the output of the commnet and applies a value decomposition nework on the top of it\n",
        "class VDN(nn.Module):\n",
        "\n",
        "  def __init__(self,linear_dim = 300,device = None):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "    self.commnet = CommNet(STATE_LENGTH,ENCODING_LENGTH,AGENTS_NUMBER,COMMUNICATION_STEPS,device)\n",
        "    self.linear_dim = linear_dim\n",
        "    self.value_stream = nn.ModuleList([nn.Sequential(nn.Linear(ENCODING_LENGTH, self.linear_dim),nn.ReLU(),nn.Linear(self.linear_dim,1)) for i in range(AGENTS_NUMBER)])\n",
        "    self.advantage_stream = nn.ModuleList([nn.Sequential(nn.Linear(ENCODING_LENGTH, self.linear_dim),nn.ReLU(),nn.Linear(self.linear_dim,5)) for i in range(AGENTS_NUMBER)])\n",
        "    self.to(device)\n",
        "\n",
        "  def forward(self,states):\n",
        "    encoded_state = self.commnet(states)\n",
        "\n",
        "    out = []\n",
        "    for agent_index in range(AGENTS_NUMBER):\n",
        "      value = self.value_stream[agent_index](encoded_state[:,agent_index,:])\n",
        "      advantage = self.advantage_stream[agent_index](encoded_state[:,agent_index,:])\n",
        "      qvals = value + (advantage - advantage.mean())\n",
        "      qvals = torch.reshape(qvals,(qvals.shape[0],1,qvals.shape[1]))\n",
        "      out.append(qvals)\n",
        "    out = torch.cat(out,axis=1)\n",
        "\n",
        "    print(\"Forward pass: \" + str(out.shape))\n",
        "\n",
        "    return out\n",
        "\n",
        "  def get_current(self,states,actions):\n",
        "    ## get the current action based on the policy network\n",
        "    q_vals = self.forward(states)\n",
        "    a = []\n",
        "    for i in range(AGENTS_NUMBER):\n",
        "      a.append(q_vals[:,i,:].gather(dim=1, index=actions[:,i].unsqueeze(-1)))\n",
        "    ##sum the action values across all the agents\n",
        "    joint_actions = torch.zeros(a[0].size()).to(self.device)\n",
        "    for i in range(AGENTS_NUMBER):\n",
        "      joint_actions = torch.add(joint_actions,a[i])\n",
        "    print(\"Joint Values: \" + str(joint_actions.shape))\n",
        "\n",
        "    return joint_actions\n",
        "\n",
        "  def get_next(self,next_states, flags):                \n",
        "    ## given the next state return the max Q value output using the target network\n",
        "    qvals = self.forward(next_states)\n",
        "    joint_qval = torch.zeros((qvals.size()[0],qvals.size()[2])).to(self.device)\n",
        "    for i in range(AGENTS_NUMBER):\n",
        "      joint_qval = torch.add(joint_qval,qvals[:,i,:]*flags[:,i,:])\n",
        "    ## return the maximum joint action value\n",
        "    next_value = joint_qval.max(dim=1)[0].detach()\n",
        "\n",
        "    print(\"Next Values: \" + str(next_value.shape))\n",
        "\n",
        "    return next_value\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52bahL0-ElM4"
      },
      "source": [
        "class CommNet(nn.Module):\n",
        "  def __init__(self,state_dimension,encoding_dimension,agents_num,communication_steps,device):\n",
        "    super().__init__()\n",
        "    self.state_dimension = state_dimension\n",
        "    self.encoding_dimension = encoding_dimension\n",
        "    self.agents_num = agents_num\n",
        "    self.communication_steps = communication_steps\n",
        "    self.device = device\n",
        "    self.to(device)\n",
        "\n",
        "    self.encoding_layer = nn.Sequential(nn.Linear(self.state_dimension, self.encoding_dimension),nn.ReLU())\n",
        "    self.WH_layer = nn.ModuleList([nn.Linear(self.encoding_dimension, self.encoding_dimension) for i in range(self.communication_steps)])\n",
        "    self.WC_layer = nn.ModuleList([nn.Linear(self.encoding_dimension, self.encoding_dimension) for i in range(self.communication_steps)])\n",
        "\n",
        "\n",
        "  def encoding_step(self,states):\n",
        "    print(\"Input shape: \" + str(states.shape))\n",
        "    ## encode the state of every agent\n",
        "    encoded_inputs = []\n",
        "    for agent_index in range(self.agents_num):\n",
        "      encoded_input = self.encoding_layer(states[:,agent_index,:])\n",
        "      encoded_input = torch.reshape(encoded_input,(encoded_input.shape[0],1,encoded_input.shape[1]))\n",
        "      encoded_inputs.append(encoded_input)\n",
        "    encoded_inputs = torch.cat(encoded_inputs,axis=1)\n",
        "    print(\"Encoded Inputs shape: \" + str(encoded_inputs.shape))\n",
        "    return encoded_inputs\n",
        "\n",
        "  def f(self,h,c,step_index):\n",
        "    ## decide which weight to use\n",
        "    return torch.tanh(self.WH_layer[step_index](h)  + self.WC_layer[step_index](c))\n",
        "\n",
        "  def communication_step(self,H,C,step_index):\n",
        "\n",
        "    print(\"Communication step: \" + str(step_index))\n",
        "\n",
        "    ## compute the next H\n",
        "    next_H = []\n",
        "    for agent_index in range(self.agents_num):\n",
        "      h = H[:,agent_index,:]\n",
        "      c = C[:,agent_index,:]\n",
        "      next_h = self.f(h,c,step_index)\n",
        "      next_h = torch.reshape(next_h,(next_h.shape[0],1,next_h.shape[1]))\n",
        "      next_H.append(next_h)\n",
        "    next_H = torch.cat(next_H,axis = 1)\n",
        "\n",
        "    print(next_H.shape)\n",
        "\n",
        "    next_C = []\n",
        "    for i in range(self.agents_num):\n",
        "      next_c = []\n",
        "      for j in range(self.agents_num):\n",
        "        if (i!=j):\n",
        "          next_c.append(next_H[:,j,:])\n",
        "      stacked_c = torch.stack(next_c,axis = 0)\n",
        "      next_c = torch.mean(stacked_c,axis = 0)\n",
        "      next_c = torch.reshape(next_c,(next_c.shape[0],1,next_c.shape[1]))\n",
        "      next_C.append(next_c)\n",
        "    next_C = torch.cat(next_C,axis = 1)\n",
        "\n",
        "    print(next_C.shape)\n",
        "\n",
        "    return next_H, next_C\n",
        "\n",
        "  def forward(self,states):\n",
        "    ## encode the state for every agent\n",
        "    encoded_states = self.encoding_step(states)\n",
        "    ## communication steps\n",
        "    ## define the first communication vector H filled with zeros\n",
        "    C0 = torch.zeros_like(encoded_states)\n",
        "    H = encoded_states\n",
        "    C = C0\n",
        "    for step in range(self.communication_steps):\n",
        "      H_new, C_new = self.communication_step(H,C,step)\n",
        "      C = C_new\n",
        "      H = H_new\n",
        "\n",
        "    return H"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qac37JRaGfO5"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYtLBi3rbmff"
      },
      "source": [
        "model = VDN(device = device)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNO4ed2uvHvl"
      },
      "source": [
        "states = np.random.rand(BATCH_SIZE,AGENTS_NUMBER,STATE_LENGTH)\n",
        "actions = np.zeros((BATCH_SIZE,AGENTS_NUMBER))\n",
        "flags = np.zeros((BATCH_SIZE,AGENTS_NUMBER,ACTIONS_NUMBER))\n",
        "\n",
        "states = torch.from_numpy(states).float().to(model.device)\n",
        "#actions = torch.from_numpy(actions).int().to(model.device)\n",
        "flags = torch.from_numpy(flags).to(model.device)\n",
        "\n",
        "actions = torch.as_tensor(actions, dtype=torch.int64).to(model.device)\n",
        "\n",
        "#get_cuda_device = flags.get_device()\n",
        "#print(get_cuda_device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJHycwogc0SA",
        "outputId": "8513a344-8bef-429c-a01d-20b3456054e3"
      },
      "source": [
        "_ = model.forward(states)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([64, 2, 50])\n",
            "Encoded Inputs shape: torch.Size([64, 2, 200])\n",
            "Communication step: 0\n",
            "torch.Size([64, 2, 200])\n",
            "torch.Size([64, 2, 200])\n",
            "Communication step: 1\n",
            "torch.Size([64, 2, 200])\n",
            "torch.Size([64, 2, 200])\n",
            "Communication step: 2\n",
            "torch.Size([64, 2, 200])\n",
            "torch.Size([64, 2, 200])\n",
            "Forward pass: torch.Size([64, 2, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybeH3VUMEOmy",
        "outputId": "f14ff2f1-0036-469c-b4ec-e16eafb1ee0f"
      },
      "source": [
        "current_values = model.get_current(states,actions)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([64, 2, 50])\n",
            "Encoded Inputs shape: torch.Size([64, 2, 200])\n",
            "Communication step: 0\n",
            "torch.Size([64, 2, 200])\n",
            "torch.Size([64, 2, 200])\n",
            "Communication step: 1\n",
            "torch.Size([64, 2, 200])\n",
            "torch.Size([64, 2, 200])\n",
            "Communication step: 2\n",
            "torch.Size([64, 2, 200])\n",
            "torch.Size([64, 2, 200])\n",
            "Forward pass: torch.Size([64, 2, 5])\n",
            "Joint Values: torch.Size([64, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUlbK_sd2pRl",
        "outputId": "ce536f1a-0cab-4a60-ac8a-822ce1531c12"
      },
      "source": [
        "next_values = model.get_next(states, flags)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input shape: torch.Size([64, 2, 50])\n",
            "Encoded Inputs shape: torch.Size([64, 2, 200])\n",
            "Communication step: 0\n",
            "torch.Size([64, 2, 200])\n",
            "torch.Size([64, 2, 200])\n",
            "Communication step: 1\n",
            "torch.Size([64, 2, 200])\n",
            "torch.Size([64, 2, 200])\n",
            "Communication step: 2\n",
            "torch.Size([64, 2, 200])\n",
            "torch.Size([64, 2, 200])\n",
            "Forward pass: torch.Size([64, 2, 5])\n",
            "Next Values: torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}